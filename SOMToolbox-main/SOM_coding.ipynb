{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pdcoding\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c286f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOMToolbox Parser\n",
    "#from SOMToolBox_Parse import SOMToolBox_Parse\n",
    "#idata = SOMToolBox_Parse(\"datasets/iris/iris.vec\").read_weight_file()\n",
    "#weights = SOMToolBox_Parse(\"datasets/iris/iris.wgt.gz\").read_weight_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HitHistogram\n",
    "def HitHist(_m, _n, _weights, _idata):\n",
    "    hist = np.zeros(_m * _n)\n",
    "    for vector in _idata: \n",
    "        position =np.argmin(np.sqrt(np.sum(np.power(_weights - vector, 2), axis=1)))\n",
    "        hist[position] += 1\n",
    "\n",
    "    return hist.reshape(_m, _n)\n",
    "\n",
    "#U-Matrix - implementation\n",
    "def UMatrix(_m, _n, _weights, _dim):\n",
    "    U = _weights.reshape(_m, _n, _dim)\n",
    "    U = np.insert(U, np.arange(1, _n), values=0, axis=1)\n",
    "    U = np.insert(U, np.arange(1, _m), values=0, axis=0)\n",
    "    #calculate interpolation\n",
    "    for i in range(U.shape[0]): \n",
    "        if i%2==0:\n",
    "            for j in range(1,U.shape[1],2):\n",
    "                U[i,j][0] = np.linalg.norm(U[i,j-1] - U[i,j+1], axis=-1)\n",
    "        else:\n",
    "            for j in range(U.shape[1]):\n",
    "                if j%2==0: \n",
    "                    U[i,j][0] = np.linalg.norm(U[i-1,j] - U[i+1,j], axis=-1)\n",
    "                else:      \n",
    "                    U[i,j][0] = (np.linalg.norm(U[i-1,j-1] - U[i+1,j+1], axis=-1) + np.linalg.norm(U[i+1,j-1] - U[i-1,j+1], axis=-1))/(2*np.sqrt(2))\n",
    "\n",
    "    U = np.sum(U, axis=2) #move from Vector to Scalar\n",
    "\n",
    "    for i in range(0, U.shape[0], 2): #count new values\n",
    "        for j in range(0, U.shape[1], 2):\n",
    "            region = []\n",
    "            if j>0: region.append(U[i][j-1]) #check left border\n",
    "            if i>0: region.append(U[i-1][j]) #check bottom\n",
    "            if j<U.shape[1]-1: region.append(U[i][j+1]) #check right border\n",
    "            if i<U.shape[0]-1: region.append(U[i+1][j]) #check upper border\n",
    "\n",
    "            U[i,j] = np.median(region)\n",
    "\n",
    "    return U\n",
    "\n",
    "#SDH - implementation\n",
    "def SDH(_m, _n, _weights, _idata, factor, approach):\n",
    "    import heapq\n",
    "\n",
    "    sdh_m = np.zeros( _m * _n)\n",
    "\n",
    "    cs=0\n",
    "    for i in range(factor): cs += factor-i\n",
    "\n",
    "    for vector in _idata:\n",
    "        dist = np.sqrt(np.sum(np.power(_weights - vector, 2), axis=1))\n",
    "        c = heapq.nsmallest(factor, range(len(dist)), key=dist.__getitem__)\n",
    "        if (approach==0): # normalized\n",
    "            for j in range(factor):  sdh_m[c[j]] += (factor-j)/cs \n",
    "        if (approach==1):# based on distance\n",
    "            for j in range(factor): sdh_m[c[j]] += 1.0/dist[c[j]] \n",
    "        if (approach==2): \n",
    "            dmin, dmax = min(dist[c]), max(dist[c])\n",
    "            for j in range(factor): sdh_m[c[j]] += 1.0 - (dist[c[j]]-dmin)/(dmax-dmin)\n",
    "\n",
    "    return sdh_m.reshape(_m, _n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c32c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import panel as pn\n",
    "#import holoviews as hv\n",
    "#from holoviews import opts\n",
    "#hv.extension('bokeh')\n",
    "\n",
    "#hithist = hv.Image(HitHist(weights['ydim'], weights['ydim'], weights['arr'], idata['arr'])).opts(xaxis=None, yaxis=None) \n",
    "#um = hv.Image(UMatrix(weights['ydim'], weights['ydim'], weights['arr'], 4)).opts(xaxis=None, yaxis=None) \n",
    "#sdh = hv.Image(SDH(weights['ydim'], weights['ydim'], weights['arr'], idata['arr'], 25, 0)).opts(xaxis=None, yaxis=None)   \n",
    "\n",
    "#hv.Layout([hithist.relabel('HitHist').opts(cmap='kr'), \n",
    "#           um.relabel('U-Matrix').opts(cmap='jet'), sdh.relabel('SDH').opts(cmap='viridis')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755620e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69136b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SOMToolBox_Parse:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "\n",
    "    def read_weight_file(self,):\n",
    "        df = pd.DataFrame()\n",
    "        if self.filename[-3:len(self.filename)] == '.gz':\n",
    "            with gzip.open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "        else:\n",
    "            with open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "\n",
    "        file.close()            \n",
    "        return df.astype('float64'), vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _read_vector_file_to_df(self, df, file):\n",
    "        xdim, ydim, vec_dim, position = 0, 0, 0, 0\n",
    "        for byte in file:\n",
    "            line = byte.decode('UTF-8')\n",
    "            if line.startswith('$'):\n",
    "                xdim, ydim, vec_dim = self._parse_vector_file_metadata(line, xdim, ydim, vec_dim)\n",
    "                if xdim > 0 and ydim > 0 and len(df.columns) == 0:\n",
    "                    df = pd.DataFrame(index=range(0, ydim * xdim), columns=range(0, vec_dim))\n",
    "            else:\n",
    "                if len(df.columns) == 0 or vec_dim == 0:\n",
    "                    raise ValueError('Weight file has no correct Dimensional information.')\n",
    "                position = self._parse_weight_file_data(line, position, vec_dim, df)\n",
    "        return df, vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _parse_weight_file_data(self, line, position, vec_dim, df):\n",
    "        splitted=line.split(' ')\n",
    "        try:\n",
    "            df.values[position] = list(np.array(splitted[0:vec_dim]).astype(float))\n",
    "            position += 1\n",
    "        except: raise ValueError('The input-vector file does not match its unit-dimension.') \n",
    "        return  position\n",
    "\n",
    "\n",
    "    def _parse_vector_file_metadata(self, line, xdim, ydim, vec_dim):\n",
    "        splitted = line.split(' ')\n",
    "        if splitted[0] == '$XDIM':      xdim = int(splitted[1])\n",
    "        elif splitted[0] == '$YDIM':    ydim = int(splitted[1])\n",
    "        elif splitted[0] == '$VEC_DIM': vec_dim = int(splitted[1])\n",
    "        return xdim, ydim, vec_dim  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fba553",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e7c10",
   "metadata": {},
   "source": [
    "For the evaluation of the different implementations we have used two datasets and two sizes of SOM. (40x20 -small and a 100x60 - large)\n",
    "\n",
    "The first dataset is the so called chain link data set that contains two two-dimensional rings which are intertwined in a three-dimensional space. \n",
    "\n",
    "The second dataset is the so called 10 clusters dataset. The clusters were generated from 10-dimensional gaussian distributions with different densities. \n",
    "\n",
    "The comparison of the visualisations can be found in the `visualisation_report.md` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368a2da",
   "metadata": {},
   "source": [
    "Chainlink dataset          |  Clusters dataset |\n",
    ":-------------------------:|:-------------------------:|\n",
    "![](pics/chainlink-info.PNG) | ![](pics/10clusters-info.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080ffd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minisom as som\n",
    " \n",
    "\n",
    "from somtoolbox import SOMToolbox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "small_m, small_n = 40, 20\n",
    "large_m, large_n = 100, 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da32f22",
   "metadata": {},
   "source": [
    "# Chainlink 40x20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa3839",
   "metadata": {},
   "source": [
    "A minisom som is trained with sigma=7, learning_rate=0.7 and iterations=1000000 using the chainlink dataset. We  produce Topographic error visualisation with parameters 4 unit and 8 unit neighborhoods and an intrinsic distance visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "chainlink = SOMToolBox_Parse('datasets/chainlink.vec')\n",
    "idata, idim, idata_x, idata_y = chainlink.read_weight_file()\n",
    "idata = MinMaxScaler().fit_transform(idata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8449cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "chainlink_small = som.MiniSom(small_m, small_n, idim, sigma=7, learning_rate=0.7)\n",
    "chainlink_small.train_random(idata, 1000000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21825bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from somtoolbox import SOMToolbox\n",
    "sm = SOMToolbox(weights=chainlink_small._weights.reshape(-1,idim),m= small_m, n= small_n,dimension=idim, input_data=idata)\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e58f2f",
   "metadata": {},
   "source": [
    "# Chainlink 100x60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c89823",
   "metadata": {},
   "source": [
    "A minisom som is trained with sigma=6, learning_rate=0.7 and iterations=500000 using the chainlink dataset. We  produce a Topographic error visualisation with parameters 4 unit and 8 unit neighborhoods and an intrinsic distance visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d38bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "chainlink_large = som.MiniSom(large_m, large_n, idim, sigma=6, learning_rate=0.7)\n",
    "chainlink_large.train_random(idata, 500000, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8024e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SOMToolbox(weights=chainlink_large._weights.reshape(-1,idim), m=large_m, n=large_n, dimension=idim, input_data=idata)\n",
    "\n",
    "\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f9547",
   "metadata": {},
   "source": [
    "# Clusters 40x20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7aaa49",
   "metadata": {},
   "source": [
    "A minisom som is trained with sigma=7, learning_rate=0.7 and iterations=1000000 using the clusters dataset. We produce two Topographic error visualisations with parameters 4 unit and 8 unit neighborhoods and an intrinsic distance visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e638a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "clusters = SOMToolBox_Parse('datasets/clusters.vec')\n",
    "idata, idim, idata_x, idata_y = clusters.read_weight_file()\n",
    "idata = MinMaxScaler().fit_transform(idata)\n",
    "clusters_dim = idata.shape[-1]\n",
    "from somtoolbox import SOMToolbox\n",
    "#clusters_small = som.MiniSom(small_m, small_n, clusters_dim, sigma=0.8, learning_rate=0.7)\n",
    "#clusters_small.train_random(idata, 10000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_large = som.MiniSom(small_m, small_n, idim, sigma=7, learning_rate=0.7)\n",
    "clusters_large.train_random(idata, 1000000, verbose=True)\n",
    "\n",
    "sm = SOMToolbox(weights=clusters_large._weights.reshape(-1,idim), m=small_m, n=small_n, dimension=idim, input_data=idata)\n",
    "\n",
    "\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ca0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm1 = SOMToolbox(weights=som._weights.reshape(-1,idim), m=small_m, n=small_n, dimension=idim, input_data=idata)\n",
    "\n",
    "sm1._mainview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87eab5",
   "metadata": {},
   "source": [
    "# Clusters 100x60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf58b7",
   "metadata": {},
   "source": [
    "A minisom som is trained with sigma=7, learning_rate=0.7 and iterations=500000 using the clusters dataset. We produce two Topographic error visualisations with parameters 4 unit and 8 unit neighborhoods and an intrinsic distance visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aca03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from somtoolbox import SOMToolbox\n",
    "\n",
    "\n",
    "clusters_large = som.MiniSom(large_m, large_n, clusters_dim, sigma=7, learning_rate=0.7)\n",
    "clusters_large.train_random(idata, 500000, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SOMToolbox(weights=som._weights.reshape(-1,idim), m=large_m, n=large_n, dimension=idim, input_data=idata)\n",
    "\n",
    "\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7152b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SOMToolbox(weights=clusters_large._weights.reshape(-1,idim), m=large_m, n=large_n, dimension=idim, input_data=idata)\n",
    "\n",
    "\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8426c0",
   "metadata": {},
   "source": [
    "# Comparison with java SOMToolbox visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c07e2",
   "metadata": {},
   "source": [
    "To compare visualisations created in the java som toolbox with visualisation created in our python implementation from the pretrained soms. We are using both cluster dataset and chainlink dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a59668",
   "metadata": {},
   "source": [
    "## Clusters dataset Java Pre-Trained SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e0c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SOMToolBox_Parse import SOMToolBox_Parse\n",
    "idata = SOMToolBox_Parse(\"datasets/clusters.vec\").read_weight_file()\n",
    "weights = SOMToolBox_Parse(\"datasets/cluster_100x60.wgt.gz\").read_weight_file()\n",
    "classes = SOMToolBox_Parse(\"datasets/10clusters.cls\").read_weight_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from somtoolbox import SOMToolbox\n",
    "\n",
    "sm = SOMToolbox(weights=weights['arr'],m=weights['ydim'],n=weights['xdim'],\n",
    "                dimension=weights['vec_dim'], input_data=idata['arr'],\n",
    "               classes=classes['arr'], component_names=classes['classes_names'])\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace43e89",
   "metadata": {},
   "source": [
    "## Chainlink dataset Java Pre-Trained SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SOMToolBox_Parse import SOMToolBox_Parse\n",
    "idata = SOMToolBox_Parse(\"datasets/chainlink.vec\").read_weight_file()\n",
    "weights = SOMToolBox_Parse(\"datasets/chainlink_40x20_1.wgt.gz\").read_weight_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from somtoolbox import SOMToolbox\n",
    "\n",
    "sm = SOMToolbox(weights=weights['arr'],m=weights['ydim'],n=weights['xdim'],\n",
    "                dimension=weights['vec_dim'], input_data=idata['arr'],\n",
    "               )\n",
    "sm._mainview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaedcee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c627be1547c7c874688ddee1aaaa67b367275f1752d282bff5eb427acd241334"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
